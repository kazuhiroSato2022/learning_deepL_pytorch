{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [オンライン開催]PyTorchで学ぶ深層学習入門第1回\n"
      ],
      "metadata": {
        "id": "VdY6Rg2XlvLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section1. 深層学習(Deep Learning: ディープラーニング)について\n",
        "昨今話題となっている、[openAI](https://openai.com/)が開発する文章生成言語モデル [GPT(Generative Pre-trained Transfomer)](https://aiacademy.jp/media/?p=1016) と呼ばれるシリーズでも深層学習の技術が使われています。手法やアルゴリズムは多種多様にあるものの、共通することは\n",
        "『機械が自動でタスクを行うための複雑で非線形なプロセスを、効果的に近似できるアルゴリズムや手法』である\n",
        "といえます。\n",
        "\n",
        "深層学習がもたらした、『革命』があります。  \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ld4zik5S6-3cPtLG_yoRz0VRwxnpVNV8\" width=100%>\n",
        "\n",
        "2000年代から2010年代前半、多くのシステムは特徴量エンジニアリングに強く依存する機械学習システムとなっていました（います。）  \n",
        "\n",
        "特徴量とは入力データを変換したものです。分類問題などのアルゴリズムを使用して訓練に使用していない新規のサンプルデータを、正確に予測するために大切なプロセスとなります。  \n",
        "的確な特徴量エンジニアリングを実施できれば、その後のプロセスにある機械学習アルゴリズムが、より正確にタスクをこなすことができるようになります。  \n",
        "\n",
        "一方で、深層学習は、課題を解くために生の入力データからそのような特徴量を自動で見つけ出します。  \n",
        "深層学習には特徴量エンジニアリングが必要ではない、ということではなく場合によってタスクによって事前に知識を与える必要があります。ただし、深層学習の、ニューラルネットワークの最大の強みは大量のデータに基づいて有益な特徴量表現を、自動で抽出することが可能であることです。  \n",
        "\n",
        "深層学習エンジニアが行う作業としては、この有益な特徴量を作る特徴量エンジニアリングを行う作業ではなく、訓練データから自律的に有益な特徴量表現が抽出できるようにニューラルネットワークを構築することが主な作業となります。  \n",
        "\n",
        "さまざまなニュースや事例にある通り、このように自動で作成された特徴量は、ヒトが作成した特徴量よりも優れており、世界に破壊的なイノベーションやインパクトを与えたテクノロジーと同様に、深層学習が持つ特徴量生成能力が、世界に大きな変化を与えることとなりました。\n",
        "\n",
        "[人工知能の未来- ディープラーニングの先にあるもの東京大学 松尾 豊](https://www.soumu.go.jp/main_content/000400435.pdf)\n"
      ],
      "metadata": {
        "id": "iBiss9ERlzVg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHbx9qohemFu"
      },
      "source": [
        "### 1-1. 機械学習の目的と分類\n",
        "\n",
        "**機械学習 (machine learning)**は、人工知能研究の1分野として「人間の学習能力や認知・判別能力を計算機上で再現する」ことを目的としています。\n",
        "\n",
        "より直接的には、機械学習では**データに潜む構造・パターンを捉える**ことが大きな目標となります。\n",
        "\n",
        "この大目標の下、データの扱い方によって機械学習は次の3つに分類されます。\n",
        "\n",
        "<ol>\n",
        "    <li><strong>教師あり学習 (supervised learning)</strong>\n",
        "    <ol>データは入力と出力からなり、中に潜む入出力関係をモデル化して捉えることで、新しい入力に対して出力を予測することができます。</ol>\n",
        "    <ol>出力が離散値なら分類、連続値なら回帰と区別することもあります。</ol>\n",
        "    </li>\n",
        "    <li><strong>教師なし学習 (unsupervised learning)</strong>\n",
        "    <ol>データには入出力の区別はなく、データ自身の生成構造や分布をモデル化して捉えることで、データの性質を知る上での参考となります。</ol>\n",
        "    </li>\n",
        "    <li><strong>強化学習 (reinforcement learning)</strong>\n",
        "    <ol>データは状態・行動・報酬からなり、これらの対応関係をモデル化して捉えることで、報酬を最大化するような行動を特定できます。</ol>\n",
        "    </li>\n",
        "</ol>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1pxSYncNhjrHkA4lig3zmD-VeOEgQlLiA\" width = 100%>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ_D2SWwemFv"
      },
      "source": [
        "### 1-2. 機械学習のプロセス\n",
        "\n",
        "機械学習を実際に行う際のプロセスを大枠でとらえると、\n",
        "\n",
        "<ol>\n",
        "    <li><strong>使用するモデルを仮定（モデル構築、モデルパラメータの設定）</strong>\n",
        "    <ol>パターンを捉えるための\"型\"がモデルです。よってモデルの良し悪し（データの持つ構造に対して適切か）が結果に大きく影響します。</ol>\n",
        "    </li>\n",
        "    <li><strong>モデルがパターンを見つけられるように学習させる（学習）</strong>\n",
        "    <ol>モデルにデータを流し込み、パターンを抽出します。</ol>\n",
        "    </li>\n",
        "    <li><strong>モデルの性能評価や利用</strong>\n",
        "    <ol>様々なモデルから最も\"良い\"モデルを選択したいので、性能評価を行います。またモデルを利用して予測や次元削減などを行います。</ol>\n",
        "    </li>\n",
        "</ol>\n",
        "\n",
        "というステップによって行うことになります。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Cx99bMpXv532SFc2xDFafu-2FsLdd22P\" width=100%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn_2u1UfemFv"
      },
      "source": [
        "### 1-3. 機械学習モデルと深層学習\n",
        "\n",
        "機械学習で用いるモデルについては様々な選択肢があります。\n",
        "\n",
        "データの集合を扱うため、統計学の知見を活かした統計モデルも頻繁に用いられてきました。\n",
        "\n",
        "といっても、統計学的な発想だけではなく、人間の脳の構造に着目したモデルといった神経生理学的な発想によるモデルも存在しています。\n",
        "\n",
        "その代表例が、**多層パーセプトロン(Multi Layer Perceptron; MLP)**です。\n",
        "\n",
        "MLPでは下図のような**ニューロン (neuron)**と呼ばれる、ヒトの神経細胞の働きを模したモデルが最小単位となっています。\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1KQvGFejOzj2x0f351bdMuwllfrPGX3gu\" width=33%>\n",
        "\n",
        "このニューロンを1単位として、層状に積み重ねることでヒトの神経細胞群の働きを模したモデルが、MLPです。\n",
        "\n",
        "（一般に1つの神経細胞は、複数の神経細胞から信号を受け取り、それらを総合して自ら信号を他の神経細胞に送出します）\n",
        "\n",
        "2層のMLPのモデルを表したものが下図です。（一般に入力層はカウントしません）\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CRsm19M9YM-4UYNr_wq6URpGg2pcJJKt\" width=70%>\n",
        "\n",
        "出典:https://zero2one.jp/ai-word/multi-layer-perceptron/\n",
        "\n",
        "**深層学習 (deep leaning)**とは、この隠れ層（中間層）を複数に増やし、全体として3層以上の多層にしたMLPモデルを用いた機械学習のことを指しています。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-4. まずは何も考えずに実行してみましょう"
      ],
      "metadata": {
        "id": "P7mQLpKzEVWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch には、データを操作するための2つの基本的なクラスメソッドがあります: `torch.utils.data.DataLoader`と`torch.utils.data.Dataset`  \n",
        "Datasetサンプルとそれに対応するラベルを格納し、`DataLoaderiterable` でDatasetをWrap(ラップ)します。"
      ],
      "metadata": {
        "id": "3IH0BLJPkx6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_PaEvWTk8rn"
      },
      "outputs": [],
      "source": [
        "import torch # Pytorchのライブラリをインポート\n",
        "from torch import nn # ニューラル・ネット\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FashionMNISTの訓練データをダウンロードする\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# FashionMNISTのテストデータをダウンロードする\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "IadEAaR5k_R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# バッチサイズ\n",
        "batch_size = 64\n",
        "\n",
        "# DataLoaderに、訓練データとテストデータを、バッチサイズ64として渡す\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L9c54tBlNms",
        "outputId": "07a3bb82-55f1-4ac8-e46f-4760b54cb6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CPUまたはGPUで学習させるためのクラスを作成.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# MLPっぽいモデルを定義する\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFh-x-FWlReh",
        "outputId": "1b2505c3-124d-4a57-e9a1-18a02241d67a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**モデル パラメーターの最適化**  \n",
        "モデルをトレーニングするには、損失関数 とオプティマイザが必要なので、それらを設定します"
      ],
      "metadata": {
        "id": "NmC1LJjalwmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "gkrNULwblVQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 実測値と予測値の差を計算\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 誤差逆伝播法\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "ctXilmzVlamk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "モデルが学習していることを確認するために、テストデータに対してモデルのパフォーマンスをチェックさせます"
      ],
      "metadata": {
        "id": "sOveS0rzmBMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "SOw9Nufwlddt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "訓練プロセスでは、反復学習 (エポック) で定義された回数分、訓練が実行されます。  \n",
        "各エポック中に、モデルはパラメーターを学習して、より良い予測を行います。各エポックでのモデルの精度と損失を出力させます"
      ],
      "metadata": {
        "id": "gETVB5mtmP0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cnhl1WXld5r",
        "outputId": "2a98a67a-ec9e-4253-e75f-37ade840edbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.307320  [   64/60000]\n",
            "loss: 2.287009  [ 6464/60000]\n",
            "loss: 2.269516  [12864/60000]\n",
            "loss: 2.262248  [19264/60000]\n",
            "loss: 2.245931  [25664/60000]\n",
            "loss: 2.227395  [32064/60000]\n",
            "loss: 2.225846  [38464/60000]\n",
            "loss: 2.190965  [44864/60000]\n",
            "loss: 2.182965  [51264/60000]\n",
            "loss: 2.162464  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.1%, Avg loss: 2.147441 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.156337  [   64/60000]\n",
            "loss: 2.142998  [ 6464/60000]\n",
            "loss: 2.086422  [12864/60000]\n",
            "loss: 2.102398  [19264/60000]\n",
            "loss: 2.058031  [25664/60000]\n",
            "loss: 2.007477  [32064/60000]\n",
            "loss: 2.022661  [38464/60000]\n",
            "loss: 1.939172  [44864/60000]\n",
            "loss: 1.936882  [51264/60000]\n",
            "loss: 1.885067  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 57.5%, Avg loss: 1.868828 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.898804  [   64/60000]\n",
            "loss: 1.871154  [ 6464/60000]\n",
            "loss: 1.752955  [12864/60000]\n",
            "loss: 1.792706  [19264/60000]\n",
            "loss: 1.700365  [25664/60000]\n",
            "loss: 1.651381  [32064/60000]\n",
            "loss: 1.666639  [38464/60000]\n",
            "loss: 1.559034  [44864/60000]\n",
            "loss: 1.586119  [51264/60000]\n",
            "loss: 1.495525  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.3%, Avg loss: 1.505005 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.565700  [   64/60000]\n",
            "loss: 1.536960  [ 6464/60000]\n",
            "loss: 1.388129  [12864/60000]\n",
            "loss: 1.462601  [19264/60000]\n",
            "loss: 1.362536  [25664/60000]\n",
            "loss: 1.348482  [32064/60000]\n",
            "loss: 1.363918  [38464/60000]\n",
            "loss: 1.278788  [44864/60000]\n",
            "loss: 1.323245  [51264/60000]\n",
            "loss: 1.231499  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 63.0%, Avg loss: 1.252382 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.322595  [   64/60000]\n",
            "loss: 1.306747  [ 6464/60000]\n",
            "loss: 1.146274  [12864/60000]\n",
            "loss: 1.250769  [19264/60000]\n",
            "loss: 1.144266  [25664/60000]\n",
            "loss: 1.158138  [32064/60000]\n",
            "loss: 1.181002  [38464/60000]\n",
            "loss: 1.108313  [44864/60000]\n",
            "loss: 1.157953  [51264/60000]\n",
            "loss: 1.078108  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.4%, Avg loss: 1.094497 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMN-fwimlgsZ",
        "outputId": "b3eb2b84-1df9-4ce3-fde7-fed26cca7e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2asmfU9llVN",
        "outputId": "cc884a83-1606-480e-d973-933a9237a01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSWBrgULln2f",
        "outputId": "d0056366-5e58-43ce-8600-591e90a6094d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section2. ところでPyTorchって何？"
      ],
      "metadata": {
        "id": "5JOd-dw1oY3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. 深層学習フレームワーク: PyTorch\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1pmy4t5Jmi0kvgqJKwo_1g2vVcQcnOkMC\" width = 33%>\n",
        "\n",
        "PyTorchは、深層学習に関連するプロジェクトの構築を容易にしてくれるライブラリの１つとなります。Pythonをベースとした科学計算ライブラリで、PyTorchは以下に示す2つの機能を使用したいユーザーを対象としています。\n",
        "\n",
        "*   Numpyベースの演算の代わりに、GPUを用いた高速な演算の実施が可能\n",
        "*   高い柔軟性と実行速度を有したディープラーニングのプラットフォームを提供してくれる\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MwytQkeYhNC0QI1iMsMthZm8CmfTaLyn\" width = 80%>  \n",
        "出展: [PyTorch Deep Learning Framework: Speed + Usability](https://syncedreview.com/2019/12/16/pytorch-deep-learning-framework-speed-usability/)  \n",
        "  \n",
        "\n",
        "**もう少し詳しく説明すると...**\n",
        "\n",
        "類似する深層学習フレームワークであるCaffe、TensorflowおよびTheanoがありますが、これらフレームワークは高速なコンピューティングパフォーマンスを提供してくれるものの、ユーザーにとっては使いやすさと柔軟性が扱いづらいフレームワークであり、よりユーザーにとって使いやすい深層学習フレームワークとして、2016年に開発リリースされたのがPyTorchです。  \n",
        "  \n",
        "主に Facebook AI によって開発され、PyTorch開発者であるAdam Paszke、Sam Gross、Soumith Chintala、Gregory Chananおよび他17人の研究者や開発者が携わっているそう。\n",
        "\n",
        "PyTorch の革新的なパフォーマンスは、主に次の5つの戦略によって達成されました。\n",
        "\n",
        "*   PyTorchコアは、テンソルデータ構造、CPU および GPU 演算子、基本的な並列処理、および微分の演算を実装するために使用される。最も集中的な演算処理はコアによって処理されるため、効率的な C++ プログラミング言語で記述してパフォーマンスを向上させることができます。\n",
        "*   制御とデータフローは、厳密に分離されています。制御フローは Python ですが、最適化された C++ コードがホストCPU上で実行されます。\n",
        "*   メモリ割当について、独自アルゴリズムによりCUDAメモリのキャッシュを段階的に構築し、それを後の割り当てに再割り当てすることで、CUDA API (GPUを深層学習用のタスク演算に置き換えるソフトウェア)の重複利用を防ぎます。\n",
        "*   Torch.multiprocessing を使用すると、ユーザーは複数の GPUで高度な並列プログラムを実装できます。\n",
        "*   参照カウントスキームは、各テンソルの使用回数をモニタリングします。カウントがゼロになると、基になるメモリがすぐに解放されます。\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uoW7j526sT4RueS5fmpXoYcDl9BbCwja\" width = 100%>  \n",
        "出展: [PyTorch: An Imperative Style, High-Performance Deep Learning Library](https://arxiv.org/pdf/1912.01703.pdf)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4a4SkIgdohsZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU-27_tSYy0b"
      },
      "source": [
        "\n",
        "\n",
        "## 3. Tensor（テンソル, テンサー）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1. テンソルって何？\n",
        "多次元の配列として表現できるようなもの。\n",
        "画像であれ、テキストであれ、入力データはベクトルに変換されます。  \n",
        "その際に、１次元なシーケンスな配列から、２次元の配列、３次元の配列...と不動小数点を含む基本的なデータ構造としてテンソルという概念があります。  \n",
        "数学や物理学、工学を学んでいる人にとっては、テンソルと聞くと空間、参照系（モード）、それら写像や変換をイメージするかと思いますが、これら数学的なテンソルと若干異なる概念として、深層学習の実装では扱われます。深層学習におけるテンソルとは、ベクトルや行列を任意の次元数に一般化したものを指します。  \n",
        "  \n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uTyvQUa4MLzX8UR_QqfuBFu11VZ3PqH-\" width = 67%>  \n",
        "出展: [Lesson 3　NumPyによる数学計算と、数学用語の「テンソル」](https://atmarkit.itmedia.co.jp/ait/articles/1902/08/news156.html)"
      ],
      "metadata": {
        "id": "o3u5Svo9c6KY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPEmNafrDUT3"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9tnynuYAMR_"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAtJYu0nAMSF"
      },
      "source": [
        "【注意】\n",
        "\n",
        "初期化されていない行列が宣言・作成されても、実際に使用されるまで明確な値は保有していません。\n",
        "\n",
        "宣言時にメモリ上の割り当てられた適当な値が初期値として入っています。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZy0JcQ6AMSG"
      },
      "source": [
        "初期化されていない、3×5行列を生成してみましょう：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4d_varHAMSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764eba43-c636-437d-bb94-57737da2929f"
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.2866e-36, 0.0000e+00, 3.3631e-44],\n",
            "        [0.0000e+00,        nan, 6.4460e-44],\n",
            "        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n",
            "        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n",
            "        [9.2198e-39, 7.0374e+22, 1.4359e-36]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-q-OY_AMSJ"
      },
      "source": [
        "次に、乱数によって初期化された3x5行列を生成してみましょう:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk6NU9oIAMSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0b050b-3f51-4a0d-9625-1c8f229dfb2f"
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8021, 0.2195, 0.3325],\n",
            "        [0.1211, 0.7894, 0.2683],\n",
            "        [0.9716, 0.6030, 0.3051],\n",
            "        [0.1340, 0.8415, 0.5174],\n",
            "        [0.0918, 0.8619, 0.8378]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BEWXROCAMSM"
      },
      "source": [
        "long型の数値0で初期化された行列を生成する場合は次の通りです。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUBy1bDAMSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1e5021-2b50-4f37-fd03-0e8340022959"
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNMp7LS4AMSR"
      },
      "source": [
        "直接、数値を指定して行列を生成することもできます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSmaoLnAMSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d0e75b-c4be-45e2-92bf-5ac8e29d5cb1"
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgBDdfF6AMSU"
      },
      "source": [
        "その他に、すでにあるtensorをもとに、新しくtensorを生成することもできます。\n",
        "\n",
        "本メソッドで生成したテンソルは、テンソルの特性（例えばデータ型：dtypeなど）を、もとのtensorから引き継ぎます（ユーザーが値や特性を直接上書きしない限り）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P_cXyNZAMSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1626db3-ee62-4eeb-cdd3-1f0316375b5a"
      },
      "source": [
        "x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[-0.5457, -0.4552, -2.0920],\n",
            "        [-0.6641,  0.9266, -0.6764],\n",
            "        [-0.7897, -1.8249, -0.0382],\n",
            "        [ 0.3420, -0.8151,  0.2744],\n",
            "        [ 1.0132, -1.1335, -0.6098]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLygdY1nAMSX"
      },
      "source": [
        "テンソルサイズ（size）≒テンソルの形、を求めてみます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEwFrYkgAMSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1989e3a-34dd-47ca-dfc3-a2e313a71e42"
      },
      "source": [
        "print(x.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOB44xlLWtKQ"
      },
      "source": [
        "【メモ】\n",
        "\n",
        "``torch.Size``はタプルとなっているため、Pythonの通常のタプルと同様の操作が可能です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2029dArbAMSZ"
      },
      "source": [
        "**テンソルの操作（変形・変換等）**\n",
        "\n",
        "\n",
        "PyTorchにはテンソルに対する操作（変形・変換等）が多く用意されています。\n",
        "\n",
        "ここで、tensorを操作（変形・変換等）する追加の例を紹介します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I41xxUFXmtP"
      },
      "source": [
        "補足: 用例1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4OnVKj5AMSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ecf6870-8e3b-4ff5-d663-96444bc03d55"
      },
      "source": [
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2193, -0.1546, -2.0828],\n",
            "        [ 0.1319,  1.4161, -0.4847],\n",
            "        [-0.5198, -0.9983,  0.3438],\n",
            "        [ 0.4004, -0.6043,  0.5200],\n",
            "        [ 1.4458, -1.1206,  0.2682]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dznbfngYAMSc"
      },
      "source": [
        "補足: 用例2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_YL8Q8nAMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518ab380-14be-49d5-b16c-dbc55f5ee721"
      },
      "source": [
        "print(torch.add(x, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2193, -0.1546, -2.0828],\n",
            "        [ 0.1319,  1.4161, -0.4847],\n",
            "        [-0.5198, -0.9983,  0.3438],\n",
            "        [ 0.4004, -0.6043,  0.5200],\n",
            "        [ 1.4458, -1.1206,  0.2682]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEjgcYv_AMSe"
      },
      "source": [
        "補足: 出力先を引数で指定 \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQCoVYYEAMSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f144cd2f-4834-4f72-8fca-e1df025f2303"
      },
      "source": [
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2193, -0.1546, -2.0828],\n",
            "        [ 0.1319,  1.4161, -0.4847],\n",
            "        [-0.5198, -0.9983,  0.3438],\n",
            "        [ 0.4004, -0.6043,  0.5200],\n",
            "        [ 1.4458, -1.1206,  0.2682]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIE94xsPAMSj"
      },
      "source": [
        "補足：テンソルそのものの変更（in-place：インプレース処理）\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF6MQ32FAMSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35331a19-ff9c-442b-d85b-887bfd500c2b"
      },
      "source": [
        "# adds x to y\n",
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8722, -1.0651, -6.2668],\n",
            "        [-1.1964,  3.2693, -1.8376],\n",
            "        [-2.0993, -4.6481,  0.2674],\n",
            "        [ 1.0844, -2.2345,  1.0687],\n",
            "        [ 3.4721, -3.3877, -0.9513]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltaptXLKAMSm"
      },
      "source": [
        "【メモ】\n",
        "\n",
        "メソッド名の後に``_``をつけることで、変数の内容を出力結果で置き換えることができます。\n",
        "\n",
        "例えば、``y.add_(x)``の場合xとyの値を加算した結果はyに上書きして、格納されます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ylKCEeObFO8"
      },
      "source": [
        "NumPyと同様、インデクシングやスライシングを行うことも可能です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSE80t58AMSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58058b0d-5cb8-4986-fbd0-4b4cf87ce49c"
      },
      "source": [
        "print(x[:, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.4552,  0.9266, -1.8249, -0.8151, -1.1335])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9zaxscAMSo"
      },
      "source": [
        "リサイズ: tensorの形を変えたい場合は ``torch.view``を使用してください:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0bTxzDvAMSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13f43c59-644c-495c-a0cd-c6725e84506f"
      },
      "source": [
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  #  -1を指定すると他に設定した次元の値から自動で計算\n",
        "print(x.size(), y.size(), z.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IqvUIL6AMSq"
      },
      "source": [
        "``.item()``を使用すると、要素を1つしか持たないtensorから、中身の数値だけを取り出すことができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB3tzjNzAMSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33bda90-5c39-4467-e5c8-599b6516f584"
      },
      "source": [
        "x = torch.randn(1)\n",
        "print(x)\n",
        "print(x.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1095])\n",
            "0.10949039459228516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyOawt7EdfJx"
      },
      "source": [
        "**参考:**\n",
        "\n",
        "PyTorchでは、転置、インデックシング、スライシング、演算処理、線形代数、乱数生成などの100を超える機能が提供されています。\n",
        "\n",
        "詳しくは[こちらのページ](https://pytorch.org/docs/stable/torch.html)をご覧ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEj9q_ktAMSt"
      },
      "source": [
        "### 3-2. NumPyとの接続\n",
        "\n",
        "PyTorchではTorch TensorからNumPy Arrayへの変換やその逆を簡単に行うことできます。\n",
        "\n",
        "（Torch TensorがCPU上にある場合）Torch TensorとNumPy Arrayはメモリ上の同じ領域に配置され、変換することができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BloXeu20gJS6"
      },
      "source": [
        "#### 3-2-1. Torch Tensorから NumPy Arrayへの変換\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISvp-esTAMSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6b89f8-cb2b-484a-895b-a483d504394f"
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLkdbh4kAMSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a439d127-df54-434d-a0d4-eef8ac03d549"
      },
      "source": [
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAlxNlTbAMSz"
      },
      "source": [
        "メモリを共有しているため、Torch Tensorの値がNumPy Arrayにも反映されることが分かります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkcVVOa8AMSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef5674d-e9b7-4d2f-ac34-2ca1b603212a"
      },
      "source": [
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySjxVQRgAMS1"
      },
      "source": [
        "#### 3-2-2. NumPy ArrayからTorch Tensorへの変換\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26bv0CakAMS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946fb784-afbd-4143-c1ba-dc5857bb85aa"
      },
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1HZ1yg4AMS4"
      },
      "source": [
        "CharTensorを除き、CPU上のすべてのTensorはNumPyへの変換、およびその逆（NumpyからTensor）に対応しています。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekIwcDFzY8i1"
      },
      "source": [
        "### 3-3. CUDA Tensors（CUDA テンソル）\n",
        "------------\n",
        "\n",
        "tensorは ``.to`` メソッドを使用することであらゆるデバイス上のメモリへと移動させることができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2STSTspeAMS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b92cfb-f72f-486e-9010-5cda9fd26a9a"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!\n",
        "\n",
        "\n",
        "# 日本語訳注：\n",
        "# tensor([1.8299], device='cuda:0')\n",
        "# tensor([1.8299], dtype=torch.float64)\n",
        "# のような出力（値は変わります）がセルのあとに表示されれば、GPUでのCUDAでのテンソル計算が成功しています。\n",
        "# もし、何も表示されなければ、Google ColaroboratoryがGPU使用モードになっていないので、\n",
        "# 下のセルの説明を読んで、GPUを使用可能な状態にしてみてください。"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.1095], device='cuda:0')\n",
            "tensor([1.1095], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}